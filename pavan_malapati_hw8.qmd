---
title: "STAT 640 : Homework 8"
author: "Pavan Malapati"
format: html
editor: visual
---

# Exercises

## Problem 3.25
```{r}
q <- c(20.74, 20.85, 20.54, 20.05, 20.08, 22.55, 19.61, 19.72, 20.34, 20.37, 
          22.69, 20.79, 21.76, 21.94, 20.31, 21.38, 20.42, 20.86, 18.80, 21.41)

# Sample size
n <- 20

# Sample mean and standard deviation
x <- mean(q)
sd <- sd(q)

# Confidence level (99%)
alpha <- 0.01

# Critical t value for 99% confidence and 19 degrees of freedom (n - 1)
t_c <- qt(1 - alpha / 2, df = n - 1)

# Margin of error for the mean
me <- t_c * (sd / sqrt(n))
```

### 1.
```{r}
# Confidence interval for the mean
ci_1 <- c(x - me, x + me)
cat("Confidence Interval for the mean: ", ci_1, "\n")
```

### 2.
```{r}
# Chi-squared critical values for variance
chi2_l <- qchisq(alpha / 2, df = n - 1)
chi2_u <- qchisq(1 - alpha / 2, df = n - 1)

# Confidence interval for the variance
ci_2 <- c(((n - 1) * sd^2) / chi2_u, ((n - 1) * sd^2) / chi2_l)
cat("Confidence Interval for the variance: ", ci_2, "\n")
```

### 3.
```{r}
# Confidence interval for the standard deviation 
ci_3 <- sqrt(ci_2)
cat("Confidence Interval for the standard deviation: ", ci_3, "\n")
```

## Problem 3.27
```{r}
X <- 17  
n <- 20  
alpha <- 1 - 0.95  

# Calculate F-distribution percentiles
F1 <- qf(1 - alpha/2, 2 * (n - X + 1), 2 * X)
F2 <- qf(1 - alpha/2, 2 * (X + 1), 2 * (n - X))

# Calculate lower and upper confidence bounds
pL <- X / (X + (n - X + 1) * F1)
pU <- (X + 1) * F2 / (n - X + (X + 1) * F2)


cat("Confidence Interval:", pL, pU)
```

# Additional Exercises

## Examples of using the generalized likelihood ratio test.

Using the `mtcars` dataset, we will compare the full model to the reduced model.  The full model includes four of the variables in the dataset.  The reduced model includes only the variables `disp` and `carb`.  The null model includes only the intercept.  We will use the `lrtest()` function from the `lmtest` package to perform the likelihood ratio test.

## Likelihood Ratio Test for Linear Regression

```{r}
#| messages = FALSE, warning = FALSE
library(lmtest)

# fit full model
model_full <- lm(mpg ~ disp + carb + hp + cyl, data = mtcars)
model_full 

# fit reduced model
model_reduced <- lm(mpg ~ disp + carb, data = mtcars)
model_reduced 

# fit null model
model_null <- lm(mpg ~ 1, data = mtcars)
model_null 

# perform likelihood ratio test for differences in models

lrtest(model_reduced, model_full) 
lrtest(model_null, model_full) 
lrtest(model_null, model_reduced) 
```

Check the calculations.  Compare the reduced and full models.
```{r}

-2*log( exp(-78.60301) / exp(-77.55790) )

-2*( - 78.60301 - (- 77.55790))

2*(  78.60301 + (- 77.55790))

pchisq(2.04522, df = 2, lower.tail = FALSE)

```

Change the Reduced Model to include the other variables in the model.

1. For the Likelihood Ratio Test for Linear Regression, change the Reduced model to *mpg ~ hp + cyl*.  Rerun the code and interpret the results.  What is the best model?
```{r}
# fit full model
model_full <- lm(mpg ~ disp + carb + hp + cyl, data = mtcars)
model_full 

# fit reduced model
model_reduced <- lm(mpg ~ hp + cyl, data = mtcars)
model_reduced 

# fit null model
model_null <- lm(mpg ~ 1, data = mtcars)
model_null 

# perform likelihood ratio test for differences in models

lrtest(model_reduced, model_full) 
lrtest(model_null, model_full) 
lrtest(model_null, model_reduced) 
```

calculations
```{r}
-2*(-80.781+77.558)
pchisq(6.446,df=2,lower.tail = FALSE)
```
Since the p-value is **less than 0.05**, we **reject the null hypothesis**. **Full model is better** compared to reduced model


## Likelihood ratio test for logistic regression

Using the `infert` dataset, we will compare the full model to the reduced model.  The full model includes two of the variables in the dataset.  The reduced model includes only the variable `induced`.  The null model includes only the intercept.  We will use the `lrtest()` function from the `lmtest` package to perform the likelihood ratio test.

```{r}
head(infert)

model_full <- glm(case ~ induced + spontaneous, family=binomial, data=infert)
model_full

model_reduced <- glm(case ~ induced, family=binomial, data=infert)
model_reduced

model_null <- glm(case ~ 1, family=binomial, data=infert)
model_null

lrtest(model_reduced, model_full)

lrtest(model_null, model_full)

lrtest(model_null, model_reduced)
```
Change the Reduced Model to include the other variables in the model.

2. For the Likelihood ratio test for logistic regression, change the Reduced model to *case ~ spontaneous*.  Rerun the code and interpret the results.  What is the best model?

```{r}
model_full <- glm(case ~ induced + spontaneous, family=binomial, data=infert)
model_full

model_reduced <- glm(case ~ spontaneous, family=binomial, data=infert)
model_reduced

model_null <- glm(case ~ 1, family=binomial, data=infert)
model_null

lrtest(model_reduced, model_full)

lrtest(model_null, model_full)

lrtest(model_null, model_reduced)
```
**Full Model (case ~ induced + spontaneous) is better than Reduced model (case ~ spontaneous)**, as evidenced by the significant p-value (0.04164).
